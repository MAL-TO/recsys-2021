{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alive-tuning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set()\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "representative-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fossil-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exceptional-legend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "coupled-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.scoring import compute_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "buried-campaign",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-clark",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "verbal-candy",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = ['tweet_timestamp']\n",
    "features = ['engaged_with_user_follower_count', 'engaged_with_user_following_count', 'engaging_user_follower_count', 'engaging_user_following_count']\n",
    "targets = ['TARGET_reply', 'TARGET_retweet', 'TARGET_retweet_with_comment', 'TARGET_like']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "continental-authority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 958 ms, sys: 223 ms, total: 1.18 s\n",
      "Wall time: 918 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet('../data/interim/sample2m.parquet', columns=(timestamp + features + targets)).sort_values('tweet_timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "willing-joshua",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-choir",
   "metadata": {},
   "source": [
    "# Timeseries holdout split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continent-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = df[df['tweet_timestamp'].dt.day < 20]\n",
    "validation_df = df[df['tweet_timestamp'].dt.day >= 20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-bowling",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-belize",
   "metadata": {},
   "source": [
    "# Train models and serialize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "breathing-filing",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_parameters = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'logloss'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "weighted-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "for target in targets:\n",
    "    dtrain = xgb.DMatrix(data=training_df[features], label=training_df[target])\n",
    "    model = xgb.train(xgb_parameters, dtrain=dtrain)\n",
    "    model.save_model(f'../models/{target}_baseline_model.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-corrections",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-valuation",
   "metadata": {},
   "source": [
    "# Define model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "composite-australian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(test_df):\n",
    "    features = ['engaged_with_user_follower_count', 'engaged_with_user_following_count', 'engaging_user_follower_count', 'engaging_user_following_count']\n",
    "    targets = ['TARGET_reply', 'TARGET_retweet', 'TARGET_retweet_with_comment', 'TARGET_like']\n",
    "    \n",
    "    # Build test DMatrix using need features\n",
    "    dtest = xgb.DMatrix(data=test_df[features])\n",
    "    \n",
    "    # Load all saved models\n",
    "    models = {}\n",
    "    for target in targets:\n",
    "        model = xgb.Booster()\n",
    "        model.load_model(f'../models/{target}_baseline_model.model')\n",
    "        models[target] = model\n",
    "\n",
    "    # Use saved models to compute predictions\n",
    "    predictions_df = pd.DataFrame()\n",
    "    for target in targets:\n",
    "        predictions_df[target] = models[target].predict(dtest)\n",
    "    \n",
    "    # Return predictions\n",
    "    return predictions_df\n",
    "\n",
    "predictions_df = model(validation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitting-carolina",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-witch",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "elder-bruce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET_reply                   AP 0.0445 and RCE -1.6484\n",
      "TARGET_retweet                 AP 0.1164 and RCE 0.7508\n",
      "TARGET_retweet_with_comment    AP 0.0095 and RCE -27.7191\n",
      "TARGET_like                    AP 0.4501 and RCE 0.8516\n"
     ]
    }
   ],
   "source": [
    "for column in predictions_df.columns:\n",
    "    print(f'{column:30}','AP {:.4f} and RCE {:.4f}'.format(\n",
    "        *compute_score(\n",
    "            validation_df[column],\n",
    "            predictions_df[column]\n",
    "        )\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
