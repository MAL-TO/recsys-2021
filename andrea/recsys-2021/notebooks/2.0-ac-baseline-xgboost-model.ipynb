{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "limiting-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format='retina'\n",
    "sns.set()\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-confidence",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-reaction",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "editorial-burst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 1.09 s, total: 4.59 s\n",
      "Wall time: 5.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet('../data/interim/sample2m.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apart-wedding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2241793 entries, 0 to 2241792\n",
      "Data columns (total 22 columns):\n",
      " #   Column                              Dtype         \n",
      "---  ------                              -----         \n",
      " 0   hashtags                            object        \n",
      " 1   present_media                       object        \n",
      " 2   present_links                       object        \n",
      " 3   present_domains                     object        \n",
      " 4   tweet_type                          category      \n",
      " 5   language                            category      \n",
      " 6   tweet_timestamp                     datetime64[ns]\n",
      " 7   engaged_with_user_id                object        \n",
      " 8   engaged_with_user_follower_count    int64         \n",
      " 9   engaged_with_user_following_count   int64         \n",
      " 10  engaged_with_user_is_verified       bool          \n",
      " 11  engaged_with_user_account_creation  datetime64[ns]\n",
      " 12  engaging_user_id                    object        \n",
      " 13  engaging_user_follower_count        int64         \n",
      " 14  engaging_user_following_count       int64         \n",
      " 15  engaging_user_is_verified           bool          \n",
      " 16  engaging_user_account_creation      datetime64[ns]\n",
      " 17  engagee_follows_engager             bool          \n",
      " 18  TARGET_reply                        int64         \n",
      " 19  TARGET_retweet                      int64         \n",
      " 20  TARGET_retweet_with_comment         int64         \n",
      " 21  TARGET_like                         int64         \n",
      "dtypes: bool(3), category(2), datetime64[ns](3), int64(8), object(6)\n",
      "memory usage: 301.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "stainless-block",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2241793, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df[['engaged_with_user_follower_count', 'engaged_with_user_following_count', 'engaging_user_follower_count', 'engaging_user_following_count']].values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "inclusive-looking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2241793,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['TARGET_reply'].values\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impressive-desktop",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-tongue",
   "metadata": {},
   "source": [
    "# Holdout validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "academic-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "beginning-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "urban-middle",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-spell",
   "metadata": {},
   "source": [
    "This is a very imbalanced binary classification problem. Only 2.9% of the samples are positive.\n",
    "This means that a classifier which always returns 0 will achieve 97.1% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pleasant-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "familiar-motivation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.91980701153363"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum() / y_train.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "alleged-surfing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8973198274954544"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum() / y_test.shape[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-rotation",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seven-montreal",
   "metadata": {},
   "source": [
    "# Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "rubber-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, log_loss\n",
    "\n",
    "def calculate_ctr(gt):\n",
    "  positive = len([x for x in gt if x == 1])\n",
    "  ctr = positive/float(len(gt))\n",
    "  return ctr\n",
    "\n",
    "def relative_cross_entropy_score(gt, pred):\n",
    "    cross_entropy = log_loss(gt, pred)\n",
    "    data_ctr = calculate_ctr(gt)\n",
    "    strawman_cross_entropy = log_loss(gt, [data_ctr for _ in range(len(gt))])\n",
    "    return (1.0 - cross_entropy/strawman_cross_entropy)*100.0\n",
    "\n",
    "def compute_score(y_true, y_score):\n",
    "    ap = average_precision_score(y_test, y_score)\n",
    "    rce = relative_cross_entropy_score(y_test, y_score)\n",
    "    return ap, rce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-chart",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-editing",
   "metadata": {},
   "source": [
    "# Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-cancellation",
   "metadata": {},
   "source": [
    "## Most frequent class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "constitutional-application",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0290 and -662.9919\n"
     ]
    }
   ],
   "source": [
    "print('{:.4f} and {:.4f}'.format(*compute_score(y_test, np.zeros(y_test.shape[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-forwarding",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "charitable-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0289 and -661.8205\n"
     ]
    }
   ],
   "source": [
    "print('{:.4f} and {:.4f}'.format(*compute_score(y_test, np.random.rand(y_test.shape[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-auction",
   "metadata": {},
   "source": [
    "Almost no difference between predicting the most frequent class and just random predictions.\n",
    "\n",
    "In line with the leaderboard's random predictions which are around `0.0227, -822.4109`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-sharing",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-retreat",
   "metadata": {},
   "source": [
    "# XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "given-acrobat",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "union-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_instances_count = y_train.sum()\n",
    "negative_instances_count = y_train.shape[0] - y_train.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "checked-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    use_label_encoder=False,\n",
    "    scale_pos_weight=negative_instances_count / positive_instances_count,\n",
    ")\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "guilty-dodge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 1s, sys: 123 ms, total: 4min 2s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=4,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=33.248838914690786, subsample=1,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "spiritual-endorsement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0373 and -11773.7249\n"
     ]
    }
   ],
   "source": [
    "print('{:.4f} and {:.4f}'.format(*compute_score(y_test, clf.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-canyon",
   "metadata": {},
   "source": [
    "## Critique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capital-laptop",
   "metadata": {},
   "source": [
    "It performs exactly like random predictions.\n",
    "\n",
    "Also, it almost always predicts 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "described-rescue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16238"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "adapted-ultimate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    302550\n",
       "1    257899\n",
       "dtype: int64"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.predict(X_test)).value_counts()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m65",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m65"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
