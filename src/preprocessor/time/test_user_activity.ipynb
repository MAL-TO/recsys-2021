{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-labor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as ks\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col, mean\n",
    "\n",
    "\n",
    "INPUT_PATH = \"hdfs://BigDataHA/user/s277309/recsys_data/\"\n",
    "TEST = True\n",
    "\n",
    "features = [\n",
    "    # Tweet features\n",
    "    \"text_tokens\",      # List[long]    Ordered list of Bert ids corresponding to Bert tokenization of Tweet text\n",
    "    \"hashtags\",         # List[string]  Tab separated list of hastags (identifiers) present in the tweet\n",
    "    \"tweet_id\",         # String        Tweet identifier (unique)\n",
    "    \"present_media\",    # List[String]  Tab separated list of media types. Media type can be in (Photo, Video, Gif)\n",
    "    \"present_links\",    # List[string]  Tab separated list of links (identifiers) included in the Tweet\n",
    "    \"present_domains\",  # List[string]  Tab separated list of domains included in the Tweet (twitter.com, dogs.com)\n",
    "    \"tweet_type\",       # String        Tweet type, can be either Retweet, Quote, Reply, or Toplevel\n",
    "    \"language\",         # String        Identifier corresponding to the inferred language of the Tweet\n",
    "    \"tweet_timestamp\",  # Long          Unix timestamp, in sec of the creation time of the Tweet\n",
    "    \n",
    "    # Engaged-with User (i.e., Engagee) Features\n",
    "    \"engaged_with_user_id\",                 # String    User identifier\n",
    "    \"engaged_with_user_follower_count\",     # Long      Number of followers of the user\n",
    "    \"engaged_with_user_following_count\",    # Long      Number of accounts the user is following\n",
    "    \"engaged_with_user_is_verified\",        # Bool      Is the account verified?\n",
    "    \"engaged_with_user_account_creation\",   # Long      Unix timestamp, in seconds, of the creation time of the account\n",
    "    \n",
    "    # Engaging User (i.e., Engager) Features\n",
    "    \"engaging_user_id\",                     # String    User identifier   \n",
    "    \"engaging_user_follower_count\",         # Long      Number of followers of the user\n",
    "    \"engaging_user_following_count\",        # Long      Number of accounts the user is following\n",
    "    \"engaging_user_is_verified\",            # Bool      Is the account verified?\n",
    "    \"engaging_user_account_creation\",       # Long      Unix timestamp, in seconds, of the creation time of the account\n",
    "    \n",
    "    # Engagement features\n",
    "    \"engagee_follows_engager\"   # Bool  Engagee follows engager?\n",
    "]\n",
    "\n",
    "features_idx = dict(zip(features, range(len(features))))\n",
    "\n",
    "labels_idx = {\n",
    "    # Engagement features (cont.)\n",
    "    \"reply_timestamp\": 20,                  # Long      Unix timestamp (in seconds) of one of the replies, if there is at least one\n",
    "    \"retweet_timestamp\": 21,                # Long      Unix timestamp (in seconds) of the retweet by the engaging user, if there is at least one\n",
    "    \"retweet_with_comment_timestamp\": 22,   # Long      Unix timestamp (in seconds) of one of the retweet with comment by the engaging user, if there is at least one\n",
    "    \"like_timestamp\": 23                    # Long      Unix timestamp (in seconds) of the like by the engaging user, if they liked the tweet\n",
    "}\n",
    "\n",
    "labels = [l for l in labels_idx.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-context",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    INPUT_PATH = \"recsys_data_sample_generated/sample_0.0003.parquet\"\n",
    "    df = spark.read.parquet(INPUT_PATH)\n",
    "else:\n",
    "    schema = features + list(map(lambda l: f\"TARGET_{l}\", labels_idx))  # Column names\n",
    "    df = sc.textFile(INPUT_PATH).map(lambda line: line.strip().split(\"\\x01\")).toDF(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-documentary",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-session",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df  = df.toPandas().set_index(['tweet_id', 'engaging_user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "entertaining-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_activity(raw_data, features = None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        raw_data (ks.DataFrame): dataset to process for feature extraction\n",
    "    Returns: \n",
    "        new_features (Dict[ks.Series]): Each ks.Series in the dictionary is the counter of user activities\n",
    "        (appearences as engaging or engagee) inside one of the specified time windows\n",
    "    \"\"\"\n",
    "    def counter_initialization(windows):\n",
    "        return {k:0 for k in WINDOWS}\n",
    "    \n",
    "    def clean_window_counter(window_counter, user):\n",
    "        # Remove user if its counters are all 0\n",
    "        if reduce(lambda a, b: a+b, window_counter[user].values()) == 0:\n",
    "            del window_counter[user]\n",
    "    \n",
    "        \n",
    "    # Time windows in seconds\n",
    "#     WINDOWS = np.array([5, 60, 240, 480, 1440])*60\n",
    "    WINDOWS = np.array([5, 60])*60\n",
    "    j = {k:0 for k in WINDOWS} # Clean up window_counter dictionary when a sample is out of window\n",
    "    window_counter = defaultdict(lambda : counter_initialization(WINDOWS)) # Counter of appearences for each user, for each time window. Dict[Dict]\n",
    "    new_features = [] # container for the new features\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    raw_data.sort_values(by='tweet_timestamp', inplace = True)\n",
    "    \n",
    "    # We convert our to separate numpy array, sicne koalas indexing turns out to be extremely slow\n",
    "    index_col = raw_data.index.to_numpy()\n",
    "    engaged_users = raw_data['engaged_with_user_id'].to_numpy()\n",
    "    timestamps = raw_data['tweet_timestamp'].to_numpy()\n",
    "    \n",
    "    new_features = {k:[] for k in WINDOWS}\n",
    "    for idx, engaged, now in zip(index_col, engaged_users, timestamps):\n",
    "        tweet_id = idx[0]\n",
    "        engaging = idx[1]\n",
    "        \n",
    "        for time_win in WINDOWS:\n",
    "            # Remove outdated counts from windows_counter\n",
    "            while timestamps[j[time_win]] < (now - time_win):\n",
    "                user_a = index_col[j[time_win]][1]\n",
    "                user_b = engaged_users[j[time_win]]\n",
    "                \n",
    "                if window_counter[user_a][time_win] > 0:\n",
    "                    window_counter[user_a][time_win] -= 1\n",
    "                if window_counter[user_b][time_win] > 0:\n",
    "                    window_counter[user_b][time_win] -= 1\n",
    "                \n",
    "                # Remove a user if all of its counter are 0\n",
    "                clean_window_counter(window_counter, user_a)\n",
    "                clean_window_counter(window_counter, user_b)\n",
    "                \n",
    "                j[time_win] += 1\n",
    "                \n",
    "            # Generate new features for current row, and increment window counter by 1\n",
    "            new_features[time_win].append({\n",
    "                'tweet_id': tweet_id,\n",
    "                'engaging_user_id': engaging,\n",
    "                f'interactions_{time_win}': window_counter[engaging][time_win]\n",
    "            })\n",
    "            window_counter[engaging][time_win] += 1\n",
    "            window_counter[engaged][time_win] += 1\n",
    "       \n",
    "    # Convert each list of dict to a series\n",
    "    for key in new_features.keys():\n",
    "        new_features[key] = ks.DataFrame(new_features[key]).set_index(['tweet_id', 'engaging_user_id']).squeeze()\n",
    "\n",
    "    #TODO: store window_counter of active users for inference\n",
    "    return new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "growing-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_dict={'engaging_user_id': ['1','1','2','2','1','1','2','1','1','2','3','3','3'],\n",
    "           'engaged_with_user_id': ['2','2','1','3','2','3','1','3','3','1','1','1','1'],\n",
    "           'tweet_id': ['a','b','c','d','e','f','g','h','i','j','k','l','m'],\n",
    "           'tweet_timestamp' : [48120, 48120, 50300, 50400, 50600, 50760, 50860, 50900, 52300, 53300, 53720, 54000, 54100]\n",
    "          }\n",
    "test_dataframe = pd.DataFrame(test_dict).set_index(['tweet_id', 'engaging_user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "distributed-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features, window_counter = user_activity(test_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "asian-operations",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{300: tweet_id  engaging_user_id\n",
       " a         1                   0\n",
       " b         1                   1\n",
       " c         2                   0\n",
       " d         2                   1\n",
       " e         1                   1\n",
       " f         1                   1\n",
       " g         2                   1\n",
       " h         1                   3\n",
       " i         1                   0\n",
       " j         2                   0\n",
       " k         3                   0\n",
       " l         3                   1\n",
       " m         3                   1\n",
       " Name: interactions_300, dtype: int64,\n",
       " 3600: tweet_id  engaging_user_id\n",
       " a         1                   0\n",
       " b         1                   1\n",
       " c         2                   2\n",
       " d         2                   3\n",
       " e         1                   3\n",
       " f         1                   4\n",
       " g         2                   5\n",
       " h         1                   6\n",
       " i         1                   5\n",
       " j         2                   4\n",
       " k         3                   4\n",
       " l         3                   5\n",
       " m         3                   5\n",
       " Name: interactions_3600, dtype: int64}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "gross-blake",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_feature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c7effce3b5b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m new_feature.assign(tweet_timestamp = [48120, 48120, 50300, 50400, 50600, 50760, 50860, 50900, 51300, 51300, 51720, 51720, 52100],\n\u001b[0m\u001b[1;32m      2\u001b[0m                   hashtags = ['1\\t2\\t5', '4', '2\\t5', '1', '', '1\\t2\\t5', '1\\t3\\t5',\n\u001b[1;32m      3\u001b[0m                        '1\\t2\\t5', '3\\t2', '', '', '3\\t4', '4\\t2'])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_feature' is not defined"
     ]
    }
   ],
   "source": [
    "new_feature.assign(tweet_timestamp = [48120, 48120, 50300, 50400, 50600, 50760, 50860, 50900, 51300, 51300, 51720, 51720, 52100],\n",
    "                  hashtags = ['1\\t2\\t5', '4', '2\\t5', '1', '', '1\\t2\\t5', '1\\t3\\t5',\n",
    "                       '1\\t2\\t5', '3\\t2', '', '', '3\\t4', '4\\t2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "variable-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark (Yarn)",
   "language": "python",
   "name": "pyspark_yarn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
