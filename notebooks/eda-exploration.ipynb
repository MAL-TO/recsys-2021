{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "independent-syntax",
   "metadata": {},
   "source": [
    "# RecSys - Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-updating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "INPUT_PATH = \"hdfs://BigDataHA/user/s277309/recsys_data/\"\n",
    "\n",
    "features = [\n",
    "    # Tweet features\n",
    "    \"text_tokens\",      # List[long]    Ordered list of Bert ids corresponding to Bert tokenization of Tweet text\n",
    "    \"hashtags\",         # List[string]  Tab separated list of hastags (identifiers) present in the tweet\n",
    "    \"tweet_id\",         # String        Tweet identifier (unique)\n",
    "    \"present_media\",    # List[String]  Tab separated list of media types. Media type can be in (Photo, Video, Gif)\n",
    "    \"present_links\",    # List[string]  Tab separated list of links (identifiers) included in the Tweet\n",
    "    \"present_domains\",  # List[string]  Tab separated list of domains included in the Tweet (twitter.com, dogs.com)\n",
    "    \"tweet_type\",       # String        Tweet type, can be either Retweet, Quote, Reply, or Toplevel\n",
    "    \"language\",         # String        Identifier corresponding to the inferred language of the Tweet\n",
    "    \"tweet_timestamp\",  # Long          Unix timestamp, in sec of the creation time of the Tweet\n",
    "    \n",
    "    # Engaged-with User (i.e., Engagee) Features\n",
    "    \"engaged_with_user_id\",                 # String    User identifier\n",
    "    \"engaged_with_user_follower_count\",     # Long      Number of followers of the user\n",
    "    \"engaged_with_user_following_count\",    # Long      Number of accounts the user is following\n",
    "    \"engaged_with_user_is_verified\",        # Bool      Is the account verified?\n",
    "    \"engaged_with_user_account_creation\",   # Long      Unix timestamp, in seconds, of the creation time of the account\n",
    "    \n",
    "    # Engaging User (i.e., Engager) Features\n",
    "    \"engaging_user_id\",                     # String    User identifier   \n",
    "    \"engaging_user_follower_count\",         # Long      Number of followers of the user\n",
    "    \"engaging_user_following_count\",        # Long      Number of accounts the user is following\n",
    "    \"engaging_user_is_verified\",            # Bool      Is the account verified?\n",
    "    \"engaging_user_account_creation\",       # Long      Unix timestamp, in seconds, of the creation time of the account\n",
    "    \n",
    "    # Engagement features\n",
    "    \"engagee_follows_engager\"   # Bool  Engagee follows engager?\n",
    "]\n",
    "\n",
    "features_idx = dict(zip(features, range(len(features))))\n",
    "\n",
    "labels_idx = {\n",
    "    # Engagement features (cont.)\n",
    "    \"reply_timestamp\": 20,                  # Long      Unix timestamp (in seconds) of one of the replies, if there is at least one\n",
    "    \"retweet_timestamp\": 21,                # Long      Unix timestamp (in seconds) of the retweet by the engaging user, if there is at least one\n",
    "    \"retweet_with_comment_timestamp\": 22,   # Long      Unix timestamp (in seconds) of one of the retweet with comment by the engaging user, if there is at least one\n",
    "    \"like_timestamp\": 23                    # Long      Unix timestamp (in seconds) of the like by the engaging user, if they liked the tweet\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "green-concrete",
   "metadata": {},
   "source": [
    "**Additional notes regarding the dataset.**\n",
    "\n",
    "* **Negative samples** - We [the authors of the challenge] also wanted to give examples of negative interactions (i.e., this user did not engage with this item), but disclosing this information will create a privacy leak. Negative examples are items the user might have seen but not engaged with. However, a set of such examples would reveal what content was seen by users â€” this is private information. To get around this, we created the pseudo-negative dataset as follows: for each user we considered all the Tweets that were created by their followers in the considered timeframe and removed the positive examples (i.e., the Tweets that were engaged with). We sampled from the set of remaining Tweets, which does not distinguish between negative examples (items the user saw and did notengage with) and items the user did not see, thereby effectively protecting this private information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-drive",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "horizontal-smith",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "lines_rdd = sc.textFile(INPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "honey-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sample data: take a ~100MB and ~1GB random sample from the whole dataset\n",
    "# SAVE_PATH = \"recsys_sampled_data\"\n",
    "\n",
    "# hundred_mb_sample_fraction = 0.0003\n",
    "# thousand_mb_sample_fraction = 0.003\n",
    "\n",
    "# hundred_mb_sample = lines.sample(withReplacement=False, fraction=hundred_mb_sample_fraction)\n",
    "# thousand_mb_sample = lines.sample(withReplacement=False, fraction=thousand_mb_sample_fraction)\n",
    "\n",
    "# hundred_mb_sample.saveAsTextFile(os.path.join(SAVE_PATH, \"sample_100mb\"))\n",
    "# thousand_mb_sample.saveAsTextFile(os.path.join(SAVE_PATH, \"sample_1gb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simple-depth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of data points in the training set: 747694282\n"
     ]
    }
   ],
   "source": [
    "# Count total data points\n",
    "total_count = lines_rdd.count()\n",
    "\n",
    "print(f\"Total number of data points in the training set: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "under-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each line\n",
    "# Fields in each data entry are separated by the 1 character (0x31 in UTF-8).\n",
    "# https://recsys-twitter.com/code/snippets\n",
    "\n",
    "fields = lines_rdd.map(lambda line: line.split(\"\\x01\")).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-staff",
   "metadata": {},
   "source": [
    "## Tweet analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-missile",
   "metadata": {},
   "source": [
    "**Number of tweets with at least one hashtag** (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "excess-maldives",
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_lines = fields.filter(lambda fields: len(fields[features_idx[\"hashtags\"]]) > 0)\n",
    "hashtag_lines_count = hashtag_lines.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intense-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points containing one or more hashtags: 19.997261661551665%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data points containing one or more hashtags: {hashtag_lines_count/total_count*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-sound",
   "metadata": {},
   "source": [
    "## Interaction analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-strain",
   "metadata": {},
   "source": [
    "**Amount of negative samples**, i.e., data points where all labels are empty, non-interactions (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "uniform-liverpool",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_interaction_filter(fields):\n",
    "    if len(fields[labels_idx[\"reply_timestamp\"]]) == 0 and \\\n",
    "        len(fields[labels_idx[\"retweet_timestamp\"]]) == 0 and \\\n",
    "        len(fields[labels_idx[\"retweet_with_comment_timestamp\"]]) == 0 and \\\n",
    "        len(fields[labels_idx[\"like_timestamp\"]]) == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "negative_samples = fields.filter(non_interaction_filter)\n",
    "negative_samples_count = negative_samples.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "essential-sullivan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points corresponding to no interaction (negative samples): 50.25544651684256%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data points corresponding to no interaction (negative samples): {negative_samples_count/total_count*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authorized-spanish",
   "metadata": {},
   "source": [
    "**Amount of type {reply, retweet, retweet with comment, like} interactions** (%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specific-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "reply_interactions = fields.filter(lambda fields: len(fields[labels_idx[\"reply_timestamp\"]]) > 0)\n",
    "retweet_interactions = fields.filter(lambda fields: len(fields[labels_idx[\"retweet_timestamp\"]]) > 0)\n",
    "retweet_comment_interactions = fields.filter(lambda fields: len(fields[labels_idx[\"retweet_with_comment_timestamp\"]]) > 0)\n",
    "like_interactions = fields.filter(lambda fields: len(fields[labels_idx[\"like_timestamp\"]]) > 0)\n",
    "\n",
    "reply_interactions_count = reply_interactions.count()\n",
    "retweet_interactions_count = retweet_interactions.count()\n",
    "retweet_comment_interactions_count = retweet_comment_interactions.count()\n",
    "like_interactions_count = like_interactions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "severe-laugh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data points containing a reply interaction: 2.903448845687441%\n",
      "Data points containing a retweet interaction: 8.75229630283571%\n",
      "Data points containing a retweet with comment interaction: 0.7013417283295474%\n",
      "Data points containing a like interaction: 39.7228055837934%\n"
     ]
    }
   ],
   "source": [
    "# Note that these data points may contain any combination of these four interactions\n",
    "print(f\"Data points containing a reply interaction: {reply_interactions_count/total_count*100}%\")\n",
    "print(f\"Data points containing a retweet interaction: {retweet_interactions_count/total_count*100}%\")\n",
    "print(f\"Data points containing a retweet with comment interaction: {retweet_comment_interactions_count/total_count*100}%\")\n",
    "print(f\"Data points containing a like interaction: {like_interactions_count/total_count*100}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
